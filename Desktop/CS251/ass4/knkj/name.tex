\documentclass[a4paper,10pt,twocolumn]{article}
\usepackage{amsmath}
\usepackage{lipsum}
\usepackage{varwidth,amsthm}
\usepackage{collectbox,mathtools}
% \usepackage{algorithm2e}
\usepackage{algorithm,algpseudocode}
\newtheorem{theorem}{Theorem}
% \usepackage{algorithmic}
% \usepackage[linewidth=1pt]{mdframed}
% \usepackage{fontspec}
% \setmonofont{Latin Modern Mono Prop}
\usepackage{lmodern}
% \setmonofont{lmtt}
% \newfontfamily{\monott}{lmtt}
% \renewcommand*\familydefault{\ttdefault} %% Only if the base font of the document is to be typewriter style


%---------------------------------------
\title{Comparison Based Sorting Algorithms}
\author{Ankit Kumar Singh}
\date{}
\begin{document}
\maketitle
\begin{abstract}
    This document presents a brief  discussion on sorting algorithms.
    Algorithms for Quicksort is provided
    in this document and its working is explained.
    Further, a proof of lower bounds on sorting is presented
    in this document. Most of the content presented
    here is created by referring and reproducing
    contents from one of the widely followed book on
    Algorithms by Cormen et al.\cite{xen}.\textbf{We do not claim
    originality of this work.} This document is prepared
    as part of an assignment for the Software Lab
    Course (CS251) to learn \LaTeX.\\
\framebox[\columnwidth] {
    \parbox{.95\columnwidth}{
    
        Declaration: I have prepared this document using \LaTeX without any unfair means. Further,
        while the document is prepared by me, I do not claim the ownership of the ideas presented in
        this document.
    }
}
\section{Introduction}
Sorting is one of the most fundamental operations in computer science useful in numerous applications.Given a sequence of numbers as input, the output should provide a non-decreasing sequence of numbers as output. More formally, we define a sorting problem as follows \cite{xen},\\
\textbf{Input:} A sequence of n numbers \(\langle a_1, a_2, ..., a_n \rangle \)
\textbf{Output:} A reordered sequence (of size \(n\))
\(\langle a\mathrlap{'}_1, a'_2, ..., a'_n \rangle\)
of the input sequence such that 
\(a'_1 \leq a'_2 \leq ...\leq a'_n \).\\
Consider the following example. Given an input
sequence \(\langle 8, 34, 7, 9, 15, 91, 15\rangle\), a sorting algorithm
should return \(\langle 7, 8, 9, 15, 15, 34, 91\rangle\) as output.\\
A fundamental problem like sorting has attracted
many researchers who contributed with innovative
algorithms to solve the problem of sorting \emph{efficiently}\cite{martin}. Efficiency of an algorithm depends on
primarily on two aspects,
\begin{itemize}
\item \textbf{Time complexity} is a formalism that captures
running time of an algorithm in terms of the input size. Normally, \emph{asymptotic} behavior
on the input size is used to analyze the time complexity of algorithms.
\item \textbf{Space complexity} is a formalism that captures amount of memory used by an algorithm
in terms of input size. Like time complexity analysis, asymptotic analysis is used for space
complexity.
\end{itemize}
In the branch of algorithms and complexity in computer science, space complexity takes a back seat compared to time complexity. Recently, another parameter of computing i.e., energy consumption has become popular. Roy et al. \cite{roy} proposed an energy complexity model for algorithms. In this document, we will deal with time complexity of sorting algorithms.\\
One class of algorithms which are based on \emph{element comparison } are commonly known as \emph{comparison based sorting algorithms}. In this document we will provide a brief overview of {\fontfamily{lmtt}\selectfont Quicksort}, a commonly used comparison based sorting algorithm \cite{hoare}. Quicksort is a sorting algorithm based on \emph{divide and-conquer} paradigm of algorithm design. Further, we will derive the lower bound of any comparison based sorting algorithm to be \(\Omega(n \log_2 n)\)
for an input size of \(n\).
\section{Quick Sort}
Quicksort is designed as a three-step divide-andconquer
process for sorting an input sequence in
an array \cite{xen}. For any given subarray, A[i..j], the
process is as follows,\\
\textbf{Divide}: The array \(A[i..j]\) is partitioned into two
subarrays \(A[i..k]\) and \(A[k + 1..j]\) such that all elements
in \(A[i..k]\) is less than or equal to all elements
in \(A[k + 1..j]\). A partitioning procedure is called to
determine \(k\) such that at the end of partitioning,
the element at the \(k^{th}\) position (i.e., \(A[k]\)) does not
change its position in the final output array.\par
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{algorithm}
  \caption{Partition procedure of {\fontfamily{lmtt}\selectfont Quicksort} algorithm}
  \begin{algorithmic}[1]
     \Procedure{Partition}{\emph{A,i,j}}\newline
     \Comment{$A$ is an array of $N$ integers, $A[1..N]$}\newline
     \Comment{i and j are the start and end of subarray}
      \State $x \leftarrow$ $A[i]$
      \State $z \leftarrow$ $i - 1$
      \State $y \leftarrow$ $j + 1$
      \While {($true$)}
          \State $z \leftarrow z - 1$ 
          \While {$A[z] > x$}
            \State $z \leftarrow z - 1$ 
          \EndWhile
          \State $y \leftarrow y + 1$ 
          \While{$A[y] < x$}
          	\State $y \leftarrow y + 1$ 
          \EndWhile
      	  \If{$ y < z $}
          	\State \text{Swap }$ A[y] \leftrightarrow A[z]$
          \Else
          	\State\Return $z$
          \EndIf
      \EndWhile
     \EndProcedure 
  \end{algorithmic}
\end{algorithm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\textbf{Conquer:} Recursively invoke {\fontfamily{lmtt}\selectfont Quicksort} on the
two subarrays. This procedure conquers the complexity
by applying the same operations in two subarrays.\\
\textbf{Merge:} Quicksort does not require merge or combine
operation as the entire array \(A[i..j]\) is sorted
in place.\par
In the heart of {\fontfamily{lmtt}\selectfont Quicksort}, there is a partition
procedure as shown in Algorithm 1. A pivot element $x$ is selected. The first inner while loop (line
\#6) continues examining elements until it finds an
element that is smaller than or equal to the pivot element.
Similarly, the second inner while loop (line
\#9) continues examining elements until it finds an
element that is greater than or equal to the pivot
element. If indices \(y\) and \(z\) have not exchanged
their side around the pivot, the elements at \(A[y]\)
and \(A[z]\) are exchanged. Otherwise, the procedure
returns the index \(z\), such that all elements to the
left of \(z\) are smaller than or equal to \(A[z]\) and all
elements to the right of \(z\) are greater than or equal
to \(A[z]\).\par
The main recursive procedure for {\fontfamily{lmtt}\selectfont Quicksort} is 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{algorithm}
  \caption{{\fontfamily{lmtt}\selectfont Quicksort} recursion}
  \begin{algorithmic}[1]
     \Procedure{Quicksort }{\emph{A,i,j}}\newline
     \Comment{Quicksort proedure called with $A,1,N$}
      	  \If{$ i < j $}
          	\State  $k \leftarrow \Call{Partition}{A,i,j}$
          	\State  $\Call{Quicksort}{A,i,k}$
            \State  $\Call{Quicksort}{A,k+1,j}$
          \EndIf
     \EndProcedure 
  \end{algorithmic}
\end{algorithm}

presented in Algorithm 2. Initial invocation is performed by call QUICKSORT\((A, 1, N)\) where \(N\) is
the length of array N.
\subsection{Time complexity analysis of {\fontfamily{lmtt}\selectfont Quicksort}}
The worst case of {\fontfamily{lmtt}\selectfont Quicksort} occurs when an array
of length \(N\), gets partitioned into two subarrays
of size N-1 and 1 in every recursive invocation of
QUICKSORT procedure in Algorithm 2. The partitioning
procedure presented in Algorithm 1, takes
\(\Theta(n)\) time, the recurrence relation for running time
is\[ T(n)=T(n-1)+\Theta(n)\]As it is evident that $T(1) = \Theta(1)$, the recurrence is solved as follows,\begin{equation*}
\begin{split}
T(n)&=T(n-1)+\Theta(n)\\
&=\sum_{k=1}^{n}\Theta(k)\\
&=\Theta\Bigg(\sum_{k=1}^{n}k \Bigg)\\
&=\Theta(n^2)\\
\end{split}
\end{equation*}
Therefore, if the partitioning is always maximally
unbalanced, the running time is $\Theta(n^2)$. Intutively,
if an input sequence is almost sorted, {\fontfamily{lmtt}\selectfont Quicksort}
will perform poorly. In the best case, partitioning
divides the array into two equal parts. Thus, the
recurrence for the best case is given by,\[T(n) = 2T \bigg(\frac{n}{2} \bigg) + \Theta(n)\]
which evaluates to $\Theta(n \log_2 n)$. Using a comparatively
involved analysis, the average running time
of {\fontfamily{lmtt}\selectfont Quicksort} can be determined to be $O(n\lg n)$.
\section{Lower bounds on comparison sorts}
An interesting question about sorting algorithms
based on comparisons is the following: What is
the lower bound of this class of sorting algorithms?
This question is important for algorithm
researchers to further improve the sorting algorithms.
A decision tree based analysis leads to the following
theorem \cite{xen}.
\begin{theorem}
Any decision tree that sorts n elements
has height $\Omega(n\log_2(n)$.
\end{theorem}
\begin{proof}Consider a decision tree of height $h$ that sorts $n$ elements.Since there are $n!$ permutations of $n$ elements, each permutation representing a distinct sorted order, the tree must have at least $n!$ leaves. Since a binary tree of height $h$ has no more than $2^h$
leaves. So,
\begin{flalign*}\quad n!&\leq 2^h.&& \end{flalign*}
Applying logarithmic ($\log_2$), the inequality becomes,
\begin{flalign*} h &\geq \lg(n!).&& \end{flalign*}
Applying Stirlingâ€™s approximations,
\begin{flalign*} n! >\bigg(\frac{n}{e}\bigg)^{n},&& \end{flalign*}
where $e$ is natural base of logarithms.Further,\begin{equation*}
\begin{split}
h & \geq \bigg(\frac{n}{e}\bigg)^{n}\\
&=n\lg n - n\lg e\\
&=\Omega(n\lg n)\\
\end{split} 
\end{equation*}
\end{proof}
\section{Conclusion}
In this document, we have provided a discussion
on sorting algorithms. We included algorithms for
{\fontfamily{lmtt}\selectfont Quicksort} and explained its working. Further, a
proof of lower bounds on sorting is presented in this
document. Most of the content presented here is
created by referring and reproducing contents from
one of the widely followed book on Algorithms by
Cormen et al.\cite{xen}. We do not claim originality of
this work. This document is prepared as part of an
assignment for the Software Lab Course (CS251) to
learn \LaTeX
\end{abstract}

\begin{thebibliography}{4}
\bibitem{xen}
\textsc{Cormen, T. H., Leiserson, C. E., Rivest, R.L., and Stein, C.}
\textit{Introduction to Algorithms, Third Edition}, 3rd ed. The MIT Press,2009.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibitem{hoare}
\textsc{Hoare, C. A. R.} Algorithm 64: Quicksort.
\textit{Communications of ACM 4},7 (1961),321-.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibitem{martin}
\textsc{Martin} W. A. Sorting: 
\textit{ACM Computing Survey 3,},4 (1971),147-174.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\bibitem{hoare}
\bibitem{roy}
\textsc{Roy, S., Rudra, A., and Verma, A.} An energy complexity model for algorithms. In
\textit{Proceedings
of the 4th Conference on Innovations in Theoretical Computer Science},(2013),ITCS '13,pp. 283-304.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{thebibliography}
\end{document}